{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r9fCBVHHe42"
      },
      "source": [
        "# **Previous Content**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTp_O1KQQ3sF"
      },
      "source": [
        "# Pandas Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBfys4iyIAWw"
      },
      "outputs": [],
      "source": [
        "# Create an alias with the as keyword while importing\n",
        "# Now you can refer to the Pandas package as pd instead of pandas\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIe-kMEdQ77i",
        "outputId": "c7c34549-15d0-4f62-e4b3-ab97ccc27b93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   name  length_in_seconds  release_year\n",
            "0               Flowers                201          2023\n",
            "1             As it Was                163          2022\n",
            "2             Anti-Hero                201          2022\n",
            "3           Eyes Closed                194          2023\n",
            "4  Just the Way You Are                221          2010\n"
          ]
        }
      ],
      "source": [
        "# A Pandas DataFrame is a 2 dimensional data structure, like a table with rows and columns\n",
        "songs_data = {\n",
        "  \"name\": [\"Flowers\", \"As it Was\", \"Anti-Hero\", \"Eyes Closed\", \"Just the Way You Are\"],\n",
        "  \"length_in_seconds\": [201, 163, 201, 194, 221],\n",
        "  \"release_year\": [2023, 2022, 2022, 2023, 2010]\n",
        "}\n",
        "# Load songs_data into a DataFrame object\n",
        "songs_df = pd.DataFrame(songs_data)\n",
        "print(songs_df) # Notice the values are labeled with their integer indices by default (i.e., first value has index 0, second value has index 1, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnMu-zaPSAIq",
        "outputId": "f6718f06-0aaa-4188-e1aa-226204258fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   name  length_in_seconds  release_year\n",
            "a               Flowers                201          2023\n",
            "b             As it Was                163          2022\n",
            "c             Anti-Hero                201          2022\n",
            "d           Eyes Closed                194          2023\n",
            "e  Just the Way You Are                221          2010\n"
          ]
        }
      ],
      "source": [
        "# Add a list of labels to give each row a label with the index argument\n",
        "songs_df_letter_label = pd.DataFrame(songs_data, index = [\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
        "print(songs_df_letter_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTn-LkZJTOGR"
      },
      "source": [
        "# Locate Rows and Columns Using loc to Specify **Labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OU4nltWTTu1"
      },
      "outputs": [],
      "source": [
        "# Use loc to return one or more row(s) by labels\n",
        "print(songs_df.loc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXe1sl7FUz3x"
      },
      "outputs": [],
      "source": [
        "# Use a list of labels to return Row 0, 1 and 2\n",
        "print(songs_df.loc[[0, 1, 2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpADlMIBXMkV"
      },
      "outputs": [],
      "source": [
        "# Specify multiple rows of the DataFrame with from and to labels separated by a colon\n",
        "print(songs_df.loc[0: 2]) # Notice: both from and to lables are included in the result when using loc (i.e. to specify labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnng3aoFWaNG"
      },
      "outputs": [],
      "source": [
        "# Use loc to specify columns by including their labels in another list\n",
        "print(songs_df.loc[[0, 1],['name', 'release_year'] ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEq6c92Ezj4g"
      },
      "outputs": [],
      "source": [
        "# Use : to represent all the row labels\n",
        "print(songs_df.loc[:, ['name', 'release_year']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VadAx4KnzRmu"
      },
      "outputs": [],
      "source": [
        "print(songs_df.loc[[0, 1], :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ub1tYB8cOhOB"
      },
      "outputs": [],
      "source": [
        "# Alternatively, Use [] to access one column by labels\n",
        "print(songs_df['name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-epTxGuuQT-"
      },
      "outputs": [],
      "source": [
        "print(songs_df[['name', 'release_year']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-e-SE3aVQcT"
      },
      "source": [
        "**Previous Practice: Explain why the following code returns an error and debug it with loc**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3hnttJfVCGl"
      },
      "outputs": [],
      "source": [
        "print(songs_df_letter_label.loc[[0, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rh6OZnrvS2K"
      },
      "outputs": [],
      "source": [
        "print(songs_df_letter_label.loc[[\"a\", \"b\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQhsetfeNaX0"
      },
      "source": [
        "**Previous Practice: Explain why the following code returns an error and fix it**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYEiLx0NNfo8"
      },
      "outputs": [],
      "source": [
        "print(songs_df['name', 'release_year'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDu0NJkqviin"
      },
      "outputs": [],
      "source": [
        "print(songs_df[['name', 'release_year']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfH4_yapasFB"
      },
      "outputs": [],
      "source": [
        "# The following will also give an error\n",
        "print(songs_df.loc['name', 'release_year'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6P9atJhQVno"
      },
      "source": [
        "**Discussion: Explain the difference between df['name'], df[['name']], df.loc[:, 'name'] and df.loc[:, ['name']]**\n",
        "\n",
        "**Hint: Check their data types**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpUVIZxy0VDu"
      },
      "outputs": [],
      "source": [
        "songs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4lP2anXbaYZJ"
      },
      "outputs": [],
      "source": [
        "print(type(songs_df['name']))\n",
        "print(songs_df['name'].shape) # a Series has the shape (n,), where n is the number of elements\n",
        "songs_df['name'][0] # this is the same as songs_df.loc[0, 'name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HqAZ1pr_adZW"
      },
      "outputs": [],
      "source": [
        "print(type(songs_df[['name']]))\n",
        "print(songs_df[['name']].shape) # this dataframe has the shape (n, 1), where n is the number of rows, and 1 indicates a single column\n",
        "# songs_df[['name']][0] # This line will return an error because songs_df[['name']] is not a pandas series\n",
        "songs_df[['name']].loc[0, 'name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BWBh28DzajqI"
      },
      "outputs": [],
      "source": [
        "print(type(songs_df.loc[:, 'name']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59Q_pZn4aop5"
      },
      "outputs": [],
      "source": [
        "print(type(songs_df.loc[:, ['name']]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-bcGH7IX4FT"
      },
      "source": [
        "# Locate Rows and Columns Using iloc to Specify **Integer Indices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQzTlNZFYNJH"
      },
      "outputs": [],
      "source": [
        "# Use iloc to return one row by integer index\n",
        "print(songs_df_letter_label.iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKRq91vnYXDw"
      },
      "outputs": [],
      "source": [
        "# Use a list of integer indices to return Row 0 and 1 of the songs_df_letter_label dataframe\n",
        "print(songs_df_letter_label.iloc[[0, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gyj25FUEY3Jx"
      },
      "outputs": [],
      "source": [
        "# Specify multiple rows of the DataFrame with from and to labels separated by a colon\n",
        "print(songs_df_letter_label.iloc[0: 2]) # Notice: the to index is excluded from the result (ATTENTION: this is DIFFERENT from loc!!!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQQ9TJd7Zar8"
      },
      "source": [
        "**Practice 1: Explain why the following code returns an error and debug it using iloc and loc**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZMRx94kZJsN"
      },
      "outputs": [],
      "source": [
        "print(songs_df_letter_label.iloc[[0, 1], ['name', 'release_year']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooLiuRaW4AtJ"
      },
      "outputs": [],
      "source": [
        "songs_df_letter_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4Nz9ICj31kL"
      },
      "outputs": [],
      "source": [
        "print(songs_df_letter_label.loc[['a','b'], ['name', 'release_year']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94xggeZJ4L0u"
      },
      "outputs": [],
      "source": [
        "print(songs_df_letter_label.iloc[[0, 1], [0, 2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AnbG-EIZ0Hq"
      },
      "source": [
        "# Read CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED8PEKKDZzj7"
      },
      "outputs": [],
      "source": [
        "# Load the CSV into a dataframe\n",
        "sales = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sales_data.csv')\n",
        "print(sales) # If the dataframe has many rows, Pandas will only return the first 5 rows and the last 5 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8PD1nqyWGes"
      },
      "outputs": [],
      "source": [
        "# Use to_string() to print the entire dataframe\n",
        "# This is helpful for viewing a large dataset in its entirety\n",
        "print(sales.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6G77iu3_yMT0"
      },
      "outputs": [],
      "source": [
        "# Colab Notebook gives a nice grid view of the dataframe\n",
        "sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6XwTokSbo4B"
      },
      "outputs": [],
      "source": [
        "# The head() method returns the headers and a specified number of rows, starting from the top\n",
        "print(sales.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcY_F5vBbyAB"
      },
      "outputs": [],
      "source": [
        "# Use info() to get more information about the dataframe\n",
        "print(sales.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTZbo5Z_7PUj"
      },
      "outputs": [],
      "source": [
        "sales['Price'].describe() # use the describe() to get a statistical description of a column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q10CuVWe4kv"
      },
      "outputs": [],
      "source": [
        "# sales['Price'].describe() # use the describe() to get a statistical description of a column\n",
        "sales.describe() # get a statistical description of the entire dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "909IFyzofp7G"
      },
      "source": [
        "# Correct Wrong Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmASstk0fs61"
      },
      "outputs": [],
      "source": [
        "# Suppose after double checking, we conclude the price in Row 0 should not be 2099.00\n",
        "# One way to fix wrong values is to replace them with correct values\n",
        "sales.loc[0, 'Price'] = 20.99 # loc locates values by labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa4od5RtifzM"
      },
      "source": [
        "You may not be able to replace the wrong data one by one for big datasets. To replace wrong data for larger data sets you can create some rules. For example, you can set some boundaries for legal values, and replace any values that are outside of the boundaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWiHS1CXjHdC"
      },
      "outputs": [],
      "source": [
        "sales.loc[sales['Price'] > 15, 'Price'] = 15\n",
        "print(sales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bCJu3UukDoP"
      },
      "outputs": [],
      "source": [
        "sales['Price'] > 15  # returns a pandas series of boolean values that indicate which rows satisfy the condition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8JKj9-3jsWC"
      },
      "outputs": [],
      "source": [
        "sales.loc[sales['Price'] > 15] # returns a pandas dataframe with rows corresponding to the True values in the previous pandas series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5gy5ZQOEkVk"
      },
      "outputs": [],
      "source": [
        "sales.loc[sales['Price'] > 15, 'Price']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljGuFre-lTD6"
      },
      "source": [
        "**Practice 2: Change the price of Product P001\n",
        "to 12 if the quantity of a transaction is greater than 1**\n",
        "\n",
        "**Hint: View how to filter with multiple conditions at https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9PNFjIOpOAH"
      },
      "source": [
        "# Clean Empty Cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jibGKI9BuiL"
      },
      "outputs": [],
      "source": [
        "sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uHS-qoJpb8F"
      },
      "outputs": [],
      "source": [
        "# One way to deal with empty cells is to remove rows that contain empty cells\n",
        "# This is usually OK if the dataset is big and removing a few rows will not have a big impact on the analysis results\n",
        "sales_drop_na = sales.dropna()\n",
        "print(sales_drop_na) # sales_drop_na does not have the row with index 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUlap9HNqB7b"
      },
      "outputs": [],
      "source": [
        "print(sales) # By default, dropna() returns a new dataframe and will not change the original dataframe\n",
        "# So the row with index 6 still exists in df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVAmJZ18qdpz"
      },
      "outputs": [],
      "source": [
        "sales.dropna(inplace = True)\n",
        "print(sales) # dropna(inplace = True) will NOT return a new DataFrame. Instead, it will remove all rows containing NULL values from the original dataframe\n",
        "# The row with index 6 is now removed from the sales dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqXrB4B7rVIo"
      },
      "outputs": [],
      "source": [
        "# Reload the CSV into a dataframe\n",
        "sales = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sales_data.csv')\n",
        "print(sales) # sales now has a null value in the Price column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEwjp6IEu6fC"
      },
      "outputs": [],
      "source": [
        "sales.dropna(subset=['Price'], inplace = True) # Remove rows with a NULL value in the Price column\n",
        "print(sales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al9L4lAFvICM"
      },
      "outputs": [],
      "source": [
        "# Reload the CSV into a dataframe\n",
        "sales = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sales_data.csv')\n",
        "print(sales) # sales has a null value in the Price column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xzBNn-3sGjs"
      },
      "outputs": [],
      "source": [
        "# The following code looks correct but it only returns a pandas series with the sixth position replaced by 20\n",
        "sales[\"Price\"].fillna(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gMev3OCsUMN"
      },
      "outputs": [],
      "source": [
        "print(sales) # sales still has the null value in the Price column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLf2VdvNrHXe"
      },
      "outputs": [],
      "source": [
        "# Replace NULL values in the Price column with the number 20\n",
        "sales[\"Price\"].fillna(20, inplace = True) # We need to set inplace = True so we are modifying df\n",
        "print(sales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik9OyZvkuJgK"
      },
      "outputs": [],
      "source": [
        "# Reload the dataframe and follow the suggestion in the warning message\n",
        "sales = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sales_data.csv')\n",
        "sales.fillna({\"Price\": 20}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qonqL-AZuQOf"
      },
      "outputs": [],
      "source": [
        "# Reload the dataframe and follow the suggestion in the warning message\n",
        "sales = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sales_data.csv')\n",
        "sales[\"Price\"] = sales[\"Price\"].fillna(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEQNydLdHmXT"
      },
      "source": [
        "# **New Content**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1o4G3wixcYW"
      },
      "source": [
        "# Handle Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19OLJPw1xkbo"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sales_data.csv')\n",
        "# Use duplicated() to discover duplicates\n",
        "# duplicated() returns a Boolean value for each row, i.e., True for every row that is a duplicate, othwerwise False\n",
        "print(df.duplicated())\n",
        "# Note that Rows with index 8 and 9 are the same\n",
        "# Row 8 is not a duplicate, and Row 9 is a duplicate\n",
        "# Documentation at https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html: the keep parameter by default is 'first'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKC4W6hUyNzp"
      },
      "outputs": [],
      "source": [
        "# Use drop_duplicates() to remove duplicates\n",
        "df.drop_duplicates(inplace = True) # We set inplace = True to make sure that the method does NOT return a new dataframe, but it will remove all duplicates from the original dataframe\n",
        "print(df)\n",
        "# Note that Row 8 is kept, and Row 9 is removed\n",
        "# Documentation at https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html: the keep parameter by default is 'first'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBkKMNB2zwH8"
      },
      "outputs": [],
      "source": [
        "# Reload the CSV into a dataframe\n",
        "sales = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sales_data.csv')\n",
        "print(sales) # sales has a null value in the Price column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2AKdoDk06dY"
      },
      "outputs": [],
      "source": [
        "# To drop duplicated rows based on one column's value in a pandas DataFrame, you can use the drop_duplicates() and specify the column name using the subset parameter\n",
        "# By default, this method keeps the first occurrence of each duplicated row and drops the rest\n",
        "sales.drop_duplicates(subset=['Transaction_ID']) # By default, inplace = False\n",
        "# sales.drop_duplicates(subset=['Transaction_ID'], inplace = True)\n",
        "# print(sales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTwgsaGsz1C8"
      },
      "outputs": [],
      "source": [
        "# Reload the CSV into a dataframe\n",
        "sales = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sales_data.csv')\n",
        "# To drop duplicated rows based on one column's value in a pandas DataFrame, you can use the drop_duplicates() and specify the column name using the subset parameter\n",
        "# By default, this method keeps the first occurrence of each duplicated row and drops the rest (i.e.,  keep='first')\n",
        "sales.drop_duplicates(subset=['Product_ID'], keep='first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0dmATzK0UAH"
      },
      "outputs": [],
      "source": [
        "sales = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sales_data.csv')\n",
        "# Use keep='last' to drop duplicates except for the last occurrence\n",
        "sales.drop_duplicates(subset=['Product_ID'], keep='last')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lasD1g1K0g6W"
      },
      "outputs": [],
      "source": [
        "sales = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sales_data.csv')\n",
        "# Use keep=False to drop all duplicates\n",
        "sales.drop_duplicates(subset=['Product_ID'], keep=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Cf7cJCez_ME"
      },
      "source": [
        "**Practice 3: Write code to get all the unique pairs of Customer_ID and Product_ID from the \"df\" dataframe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hov6KIa4w_AZ"
      },
      "source": [
        "# Clean Date Format (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7yU0fumt8oX"
      },
      "outputs": [],
      "source": [
        "sales = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sales_data.csv')\n",
        "# Pandas has a to_datetime() method for converting cell values to dates\n",
        "sales['Date'] = pd.to_datetime(sales['Date'], format='mixed', dayfirst =False)\n",
        "print(sales)\n",
        "# Documentation at https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html:\n",
        "# Use format='mixed' to infer the format for each element individually. This is risky, so we set dayfirst = False which indicates that we don't prefer to parse with day first."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "eTn-LkZJTOGR",
        "M-bcGH7IX4FT",
        "I1o4G3wixcYW",
        "Hov6KIa4w_AZ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
